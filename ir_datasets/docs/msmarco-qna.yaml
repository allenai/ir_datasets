_:
  pretty_name: 'MSMARCO (QnA)'
  desc: '
<p>
The MS MARCO Question Answering dataset. This is the source collection of <a class="ds-ref">msmarco-passage</a>
and <a class="ds-ref">msmarco-document</a>.
</p>
<div class="warn">
It is prohibited to use information from this dataset for submissions to the MS MARCO passage and document
leaderboards or the TREC DL shared task.
</div>
<p>
Query IDs in this collection align with those found in <a class="ds-ref">msmarco-passage</a> and
<a class="ds-ref">msmarco-document</a>. The collection does not provide doc_ids, so these are assigned
in the following format: <code>[msmarco_passage_id]-[url_seq]</code>, where <code>[msmarco_passage_id]</code>
is the document from <a class="ds-ref">msmarco-passage</a> that has matching contents and <code>[url_seq]</code>
is assigned sequentially for each URL encountered. In other words, all documents with the same prefix have the
same text; they only differ in the originating document.
</p>
<p>
Doc <code>msmarco_passage_id</code> fields are assigned by matching pasasge contents in <a class="ds-ref">msmarco-passage</a>,
and this field is provided for every document. Doc <code>msmarco_document_id</code> fields are assigned by
matching the URL to the one found in <a class="ds-ref">msmarco-document</a>. Due to how <a class="ds-ref">msmarco-document</a>
was constructed, there is not necessarily a match (value will be <code class="kwd">None</code> if no match).
</p>
<ul>
  <li>Documents: Short passages (from web)</li>
  <li>Queries: Natural language questions (from query log), including type and natural-language answers.</li>
  <li><a href="https://microsoft.github.io/msmarco/#qna">Leaderboard</a></li>
  <li><a href="https://arxiv.org/abs/1611.09268">Dataset Paper</a></li>
  <li><a href="https://github.com/microsoft/MSMARCO-Question-Answering">More information</a></li>
</ul>'
  bibtex_ids: ['Bajaj2016Msmarco']

train:
  desc: '
<p>
Official train set.
</p>
<p>
The scoreddocs provides the roughtly 10 passages presented to the user for annotation,
where the score indicates the order presented.
</p>
'
  bibtex_ids: ['Bajaj2016Msmarco']

dev:
  desc: '
<p>
Official dev set.
</p>
<p>
The scoreddocs provides the roughtly 10 passages presented to the user for annotation,
where the score indicates the order presented.
</p>
'
  bibtex_ids: ['Bajaj2016Msmarco']

eval:
  desc: '
<p>
Official eval set.
</p>
<p>
The scoreddocs provides the roughtly 10 passages presented to the user for annotation,
where the score indicates the order presented.
</p>
'
  bibtex_ids: ['Bajaj2016Msmarco']
