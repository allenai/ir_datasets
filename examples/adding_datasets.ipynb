{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ir_datasets - Adding Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial covers the process for adding a new dataset to the `ir_datasets` package.\n",
    "\n",
    "This tutorial is for datasets that are inteded to be added to the main package. For an example of an extension, see [this example extension](https://github.com/seanmacavaney/dummy-irds-ext).\n",
    "\n",
    "Before starting, we recommend [opening an issue](https://github.com/allenai/ir_datasets/issues/new/choose) so various decisions about how to support the dataset can be discussed.\n",
    "\n",
    "There are four files involved in adding a dataset to the `ir_datasets` package:\n",
    " - `ir_datasets/datasets/[dataset-id].py` - Contains the definition of the dataset and any specialized code for handling it.\n",
    " - `ir_datasets/etc/downloads.json` - Contains information about how to download and verify dataset source files.\n",
    " - `ir_datasets/docs/[dataset-id].yaml` - Contains documentation of the dataset.\n",
    " - `test/integration/[dataset-id].py` - Contains automated tests to ensure the dataset is processed as expected.\n",
    " \n",
    "We will now show examples of each of these files for a toy dataset called `dummy`, with files hosted here: https://github.com/seanmacavaney/dummy-irds-ext/tree/master/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File: `ir_datasets/datasets/dummy.py`\n",
    "\n",
    "```python\n",
    "import ir_datasets\n",
    "from ir_datasets.formats import TsvDocs, TsvQueries, TrecQrels\n",
    "\n",
    "# A unique identifier for this dataset. This should match the file name (with \"-\" instead of \"_\")\n",
    "NAME = 'dummy'\n",
    "\n",
    "# What do the relevance levels in qrels mean?\n",
    "QREL_DEFS = {\n",
    "    1: 'relevant',\n",
    "    0: 'not relevant',\n",
    "}\n",
    "\n",
    "# This message is shown to the user before downloads are started\n",
    "DUA = 'Please confirm that you agree to the data usage agreement at <https://some-url/>'\n",
    "\n",
    "# An initialization function is used to keep the namespace clean\n",
    "def _init():\n",
    "    # The directory where this dataset's data files will be stored\n",
    "    base_path = ir_datasets.util.home_path() / NAME\n",
    "    \n",
    "    # Load an object that is used for providing the documentation\n",
    "    documentation = YamlDocumentation(f'docs/{NAME}.yaml')\n",
    "    \n",
    "    # A reference to the downloads file, under the key \"dummy\". (DLC stands for DownLoadable Content)\n",
    "    dlc = DownloadConfig.context(NAME, base_path, dua=DUA)\n",
    "    \n",
    "    # How to process the documents. Since they are in a typical TSV format, we'll use TsvDocs.\n",
    "    # Note that other dataset formats may require you to write a custom docs handler (BaseDocs).\n",
    "    # Note that this doesn't process the documents now; it just defines how they are processed.\n",
    "    docs = TsvDocs(dlc['docs'], namespace=NAME, lang='en')\n",
    "    \n",
    "    # How to process the queries. Similar to the documents, you may need to write a custom\n",
    "    # queries handler (BaseQueries).\n",
    "    queries = TsvQueries(dlc['queries'], namespace=NAME, lang='en')\n",
    "    \n",
    "    # Qrels: The qrels file is in the TREC format, so we'll use TrecQrels to process them\n",
    "    qrels = TrecQrels(dlc['qrels'], QREL_DEFS)\n",
    "    \n",
    "    # Package the docs, queries, qrels, and documentation into a Dataset object\n",
    "    dataset = Dataset(docs, queries, qrels, documentation('_'))\n",
    "    \n",
    "    # Register the dataset in ir_datasets\n",
    "    ir_datasets.registry.register(NAME, dataset)\n",
    "    \n",
    "    return dataset # used for exposing dataset to the namespace\n",
    "\n",
    "dataset = _init()\n",
    "```\n",
    "\n",
    "Note that you also need to add this file to `ir_datasets/datasets/__init__.py`:\n",
    "\n",
    "```python\n",
    "from . import dummy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File: `ir_datasets/etc/downloads.json`\n",
    "\n",
    "(add lines like these to the file)\n",
    "\n",
    "```json\n",
    "\"dummy\": {\n",
    "  \"docs\": {\n",
    "    \"url\": \"https://raw.githubusercontent.com/seanmacavaney/dummy-irds-ext/master/data/docs.tsv\",\n",
    "    \"expected_md5\": \"c7bb5a1a3a07d51de50e8414245c2be4\",\n",
    "    \"cache_path\": \"docs.tsv\"\n",
    "  },\n",
    "  \"queries\": {\n",
    "    \"url\": \"https://raw.githubusercontent.com/seanmacavaney/dummy-irds-ext/master/data/queries.tsv\",\n",
    "    \"expected_md5\": \"08ba86d990cbe6890f727946346964db\",\n",
    "    \"cache_path\": \"queries.tsv\"\n",
    "  },\n",
    "  \"qrels\": {\n",
    "    \"url\": \"https://raw.githubusercontent.com/seanmacavaney/dummy-irds-ext/master/data/qrels\",\n",
    "    \"expected_md5\": \"79ed359fe0afa0f67eb39f468d162920\",\n",
    "    \"cache_path\": \"qrels\"\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File: `ir_datasets/docs/dummy.yaml`\n",
    "\n",
    "```yaml\n",
    "_: # matches documentation key above\n",
    "  pretty_name: 'Dummy' # a more human-readable way to present this dataset than the dataset-id\n",
    "  desc: '\n",
    "<p>\n",
    "HTML-encoded and human-readable information about this dataset.\n",
    "Include a brief description of the dataset.\n",
    "Be sure to include important decisions made when processing it.\n",
    "Also, link to more information, e.g. websites, papers, etc.\n",
    "</p>\n",
    "<ul>\n",
    "  <li><a href=\"https://github.com/seanmacavaney/dummy-irds-ext\">Link to the source</a></li>\n",
    "</ul>' \n",
    "  bibtex: |\n",
    "    @misc{dummy,\n",
    "      title={Dummy: a made-up dataset},\n",
    "      year={2021}\n",
    "    }\n",
    "```\n",
    "\n",
    "To generate the HTML documentation files, run `python -m ir_datasets documentation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File: `test/integration/dummy.py`\n",
    "\n",
    "```python\n",
    "from ir_datasets.formats import GenericQuery, GenericDoc, TrecQrel\n",
    "from .base import DatasetIntegrationTest\n",
    "\n",
    "class TestDummy(DatasetIntegrationTest):\n",
    "    def test_docs(self):\n",
    "        # Test that the dataset 'dummy' has 15 documents, and test the specific docs at indices 0, 9, and 14\n",
    "        self._test_docs('dummy', count=15, items={\n",
    "            0: GenericDoc('T1', 'CUT, CAP AND BALANCE. TAXED ENOUGH ALREADY!'),\n",
    "            9: GenericDoc('T10', 'Perhaps this is the kind of thinking we need in Washington ...'),\n",
    "            14: GenericDoc('T15', \"I've been visiting Trump Int'l Golf Links Scotland and the course will be unmatched anywhere in the world. Spectacular!\"),\n",
    "        })\n",
    "\n",
    "    def test_queries(self):\n",
    "        # Test that the dataset 'dummy' has 4 queries, and test the specific queries at indices 0 and 3\n",
    "        self._test_queries('dummy', count=4, items={\n",
    "            0: GenericQuery('1', 'republican party'),\n",
    "            3: GenericQuery('4', 'media'),\n",
    "        })\n",
    "\n",
    "    def test_qrels(self):\n",
    "        # Test that the dataset 'dummy' has 60 qrels, and test the specific qrels at indices 0, 9, and 59\n",
    "        self._test_qrels('dummy', count=60, items={\n",
    "            0: TrecQrel('1', 'T1', 0, '0'),\n",
    "            9: TrecQrel('1', 'T10', 0, '0'),\n",
    "            59: TrecQrel('4', 'T15', 0, '0'),\n",
    "        })\n",
    "```\n",
    "\n",
    "Note that within a DatasetIntegrationTest, you can use `self._build_test_docs('dummy')`, `self._build_test_queries('dummy')`, `self._build_test_qrels('dummy')` to generate sample test cases. But be sure to check that the tests they generate are properly processed, and feel free to add additional test cases, especially to test dataset-specific handlers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
