<!DOCTYPE html>
<html>
<head>
<link rel="stylesheet" href="main.css" />
<script src="https://code.jquery.com/jquery-1.12.4.min.js" integrity="sha256-ZosEbRLbNQzLpnKIkEdrPv7lOy9C27hHQ+Xp8a4MxAQ=" crossorigin="anonymous"></script>
<script src="https://code.jquery.com/ui/1.12.1/jquery-ui.min.js" integrity="sha256-VazP97ZCwtekAsvgPBSUwPFKdrwD3unUfSGVYrahUqU=" crossorigin="anonymous"></script>
<script src="main.js"></script>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="robots" content="noindex,nofollow" />
<title>DPR Wiki100 - ir_datasets</title>
<body>
<div class="page">

<div class="banner">This documentation is for <strong>master</strong>. See <a href="../dpr-w100.html">here</a> for documentation of the current latest version on pypi.</div>

<div style="position: absolute; top: 4px; left: 4px;"><a href="index.html">&larr; home</a></div>

<div style="position: absolute; top: 4px; right: 4px;">Github: <a href="https://github.com/allenai/ir_datasets/blob/master/ir_datasets/datasets/dpr_w100.py">datasets/dpr_w100.py</a></div>
<h1><code>ir_datasets</code>: DPR Wiki100</h1>
<div style="font-weight: bold; font-size: 1.1em;">Index</div>
<ol class="index">
<li><a href="#dpr-w100"><kbd>dpr-w100</kbd></a></li>
<li><a href="#dpr-w100/natural-questions/dev"><kbd><span class="prefix">dpr-w100</span>/natural-questions/dev</kbd></a></li>
<li><a href="#dpr-w100/natural-questions/train"><kbd><span class="prefix">dpr-w100</span>/natural-questions/train</kbd></a></li>
<li><a href="#dpr-w100/trivia-qa/dev"><kbd><span class="prefix">dpr-w100</span>/trivia-qa/dev</kbd></a></li>
<li><a href="#dpr-w100/trivia-qa/train"><kbd><span class="prefix">dpr-w100</span>/trivia-qa/train</kbd></a></li>
</ol>
<div id="Downloads">
</div>
<hr />
<div class="dataset" id="dpr-w100">
<h3><kbd class="select"><span class="str">"dpr-w100"</kdb></h3>

<div class="desc">
 <p> A wikipedia dump from 20 December, 2018, split into passages of 100 words. Used in experiments in the DPR paper (and other subsequent works) for retrieval experiments over Q&amp;A collections. </p> <ul> <li><a href="https://arxiv.org/pdf/2004.04906.pdf">Dataset paper</a></li> <li><a href="https://github.com/facebookresearch/DPR">Repository</a></li> </ul> 
</div>
<div class="tabs">
<a class="tab" target="dpr-w100__docs">docs</a>
<div id="dpr-w100__docs" class="tab-content">
<p>Language: <span class="lang-code">en</span></p>
<div>Document type:</div>
<div class="type">
<div class="type-name">DprW100Doc: (<span class="kwd">namedtuple</span>)</div>
<ol class="type-fields">
<li data-tuple-idx="0"><span class="">doc_id</span>: <span class="kwd">str</span></li><li data-tuple-idx="1"><span class="">text</span>: <span class="kwd">str</span></li><li data-tuple-idx="2"><span class="">title</span>: <span class="kwd">str</span></li>
</ol>
</div>
<p>Example</p>
<code class="example">
<div><span class="kwd">import</span> ir_datasets</div>
<div>dataset = ir_datasets.load(<span class="str">'dpr-w100')</div>
<div><span class="kwd">for</span> doc <span class="kwd">in</span> dataset.docs_iter():</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;doc <span class="comment"># namedtuple&lt;doc_id, text, title&gt;</span></div>
</code>
</div>

<a class="tab" target="dpr-w100__citation">Citation</a>
<div id="dpr-w100__citation" class="tab-content">
bibtex:
<cite class="select">@misc{karpukhin2020dense,
  title={Dense Passage Retrieval for Open-Domain Question Answering},
  author={Vladimir Karpukhin and Barlas Oğuz and Sewon Min and Patrick Lewis and Ledell Wu and Sergey Edunov and Danqi Chen and Wen-tau Yih},
  year={2020},
  eprint={2004.04906},
  archivePrefix={arXiv},
  primaryClass={cs.CL}
}
</cite>
</div>
</div>
</div>

<hr />
<div class="dataset" id="dpr-w100/natural-questions/dev" data-parent="dpr-w100">
<h3><kbd class="ds-name select"><span class="str">"dpr-w100/natural-questions/dev"</kdb></h3>

<div class="desc">
 <p> Dev subset from the Natural Questions Q&amp;A collection. This differs from the <a class="ds-ref">natural-questions/dev</a> dataset in that it uses the full Wikipedia dump and additional filtering (described in the DPR paper) was applied. </p> <ul> <li>See also: <a class="ds-ref">natural-questions</a></li> </ul> 
</div>
<div class="tabs">
<a class="tab" target="dpr-w100/natural-questions/dev__queries">queries</a>
<div id="dpr-w100/natural-questions/dev__queries" class="tab-content">
<p>Language: <span class="lang-code">en</span></p>
<div>Query type:</div>
<div class="type">
<div class="type-name">DprW100Query: (<span class="kwd">namedtuple</span>)</div>
<ol class="type-fields">
<li data-tuple-idx="0"><span class="">query_id</span>: <span class="kwd">str</span></li><li data-tuple-idx="1"><span class="">text</span>: <span class="kwd">str</span></li><li data-tuple-idx="2"><span class="">answers</span>: <span class="kwd">Tuple</span>[<span class="kwd">str</span>]</li>
</ol>
</div>
<p>Example</p>
<code class="example">
<div><span class="kwd">import</span> ir_datasets</div>
<div>dataset = ir_datasets.load(<span class="str">'dpr-w100/natural-questions/dev')</div>
<div><span class="kwd">for</span> query <span class="kwd">in</span> dataset.queries_iter():</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;query <span class="comment"># namedtuple&lt;query_id, text, answers&gt;</span></div>
</code>
</div>

<a class="tab" target="dpr-w100/natural-questions/dev__docs">docs</a>
<div id="dpr-w100/natural-questions/dev__docs" class="tab-content">
<p>Language: <span class="lang-code">en</span></p>
<div>Document type:</div>
<div class="type">
<div class="type-name">DprW100Doc: (<span class="kwd">namedtuple</span>)</div>
<ol class="type-fields">
<li data-tuple-idx="0"><span class="">doc_id</span>: <span class="kwd">str</span></li><li data-tuple-idx="1"><span class="">text</span>: <span class="kwd">str</span></li><li data-tuple-idx="2"><span class="">title</span>: <span class="kwd">str</span></li>
</ol>
</div>
<p>Example</p>
<code class="example">
<div><span class="kwd">import</span> ir_datasets</div>
<div>dataset = ir_datasets.load(<span class="str">'dpr-w100/natural-questions/dev')</div>
<div><span class="kwd">for</span> doc <span class="kwd">in</span> dataset.docs_iter():</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;doc <span class="comment"># namedtuple&lt;doc_id, text, title&gt;</span></div>
</code>
</div>

<a class="tab" target="dpr-w100/natural-questions/dev__qrels">qrels</a>
<div id="dpr-w100/natural-questions/dev__qrels" class="tab-content">
<div>Query relevance judgment type:</div>
<div class="type">
<div class="type-name">TrecQrel: (<span class="kwd">namedtuple</span>)</div>
<ol class="type-fields">
<li data-tuple-idx="0"><span class="">query_id</span>: <span class="kwd">str</span></li><li data-tuple-idx="1"><span class="">doc_id</span>: <span class="kwd">str</span></li><li data-tuple-idx="2"><span class="">relevance</span>: <span class="kwd">int</span></li><li data-tuple-idx="3"><span class="">iteration</span>: <span class="kwd">str</span></li>
</ol>
</div>
<p>Relevance levels</p>

<table>
<tr><th>Rel.</th><th>Definition</th></tr>
<tr><td class="relScore">-1</td><td>negative samples</td></tr>
<tr><td class="relScore">0</td><td>"hard" negative samples</td></tr>
<tr><td class="relScore">1</td><td>contains the answer text and retrieved in the top BM25 results</td></tr>
<tr><td class="relScore">2</td><td>marked by human annotator as containing the answer</td></tr>
</table>

<p>Example</p>
<code class="example">
<div><span class="kwd">import</span> ir_datasets</div>
<div>dataset = ir_datasets.load(<span class="str">'dpr-w100/natural-questions/dev')</div>
<div><span class="kwd">for</span> qrel <span class="kwd">in</span> dataset.qrels_iter():</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;qrel <span class="comment"># namedtuple&lt;query_id, doc_id, relevance, iteration&gt;</span></div>
</code>
</div>

<a class="tab" target="dpr-w100/natural-questions/dev__citation">Citation</a>
<div id="dpr-w100/natural-questions/dev__citation" class="tab-content">
bibtex:
<cite class="select">@article{Kwiatkowski2019NQ,
  title = {Natural Questions: a Benchmark for Question Answering Research},
  author = {Tom Kwiatkowski and Jennimaria Palomaki and Olivia Redfield and Michael Collins and Ankur Parikh and Chris Alberti and Danielle Epstein and Illia Polosukhin and Matthew Kelcey and Jacob Devlin and Kenton Lee and Kristina N. Toutanova and Llion Jones and Ming-Wei Chang and Andrew Dai and Jakob Uszkoreit and Quoc Le and Slav Petrov},
  year = {2019},
  journal = {TACL}
}
@misc{karpukhin2020dense,
  title={Dense Passage Retrieval for Open-Domain Question Answering},
  author={Vladimir Karpukhin and Barlas Oğuz and Sewon Min and Patrick Lewis and Ledell Wu and Sergey Edunov and Danqi Chen and Wen-tau Yih},
  year={2020},
  eprint={2004.04906},
  archivePrefix={arXiv},
  primaryClass={cs.CL}
}
</cite>
</div>
</div>
</div>

<hr />
<div class="dataset" id="dpr-w100/natural-questions/train" data-parent="dpr-w100">
<h3><kbd class="ds-name select"><span class="str">"dpr-w100/natural-questions/train"</kdb></h3>

<div class="desc">
 <p> Training subset from the Natural Questions Q&amp;A collection. This differs from the <a class="ds-ref">natural-questions/train</a> dataset in that it uses the full Wikipedia dump and additional filtering (described in the DPR paper) was applied. </p> <ul> <li>See also: <a class="ds-ref">natural-questions</a></li> </ul> 
</div>
<div class="tabs">
<a class="tab" target="dpr-w100/natural-questions/train__queries">queries</a>
<div id="dpr-w100/natural-questions/train__queries" class="tab-content">
<p>Language: <span class="lang-code">en</span></p>
<div>Query type:</div>
<div class="type">
<div class="type-name">DprW100Query: (<span class="kwd">namedtuple</span>)</div>
<ol class="type-fields">
<li data-tuple-idx="0"><span class="">query_id</span>: <span class="kwd">str</span></li><li data-tuple-idx="1"><span class="">text</span>: <span class="kwd">str</span></li><li data-tuple-idx="2"><span class="">answers</span>: <span class="kwd">Tuple</span>[<span class="kwd">str</span>]</li>
</ol>
</div>
<p>Example</p>
<code class="example">
<div><span class="kwd">import</span> ir_datasets</div>
<div>dataset = ir_datasets.load(<span class="str">'dpr-w100/natural-questions/train')</div>
<div><span class="kwd">for</span> query <span class="kwd">in</span> dataset.queries_iter():</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;query <span class="comment"># namedtuple&lt;query_id, text, answers&gt;</span></div>
</code>
</div>

<a class="tab" target="dpr-w100/natural-questions/train__docs">docs</a>
<div id="dpr-w100/natural-questions/train__docs" class="tab-content">
<p>Language: <span class="lang-code">en</span></p>
<div>Document type:</div>
<div class="type">
<div class="type-name">DprW100Doc: (<span class="kwd">namedtuple</span>)</div>
<ol class="type-fields">
<li data-tuple-idx="0"><span class="">doc_id</span>: <span class="kwd">str</span></li><li data-tuple-idx="1"><span class="">text</span>: <span class="kwd">str</span></li><li data-tuple-idx="2"><span class="">title</span>: <span class="kwd">str</span></li>
</ol>
</div>
<p>Example</p>
<code class="example">
<div><span class="kwd">import</span> ir_datasets</div>
<div>dataset = ir_datasets.load(<span class="str">'dpr-w100/natural-questions/train')</div>
<div><span class="kwd">for</span> doc <span class="kwd">in</span> dataset.docs_iter():</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;doc <span class="comment"># namedtuple&lt;doc_id, text, title&gt;</span></div>
</code>
</div>

<a class="tab" target="dpr-w100/natural-questions/train__qrels">qrels</a>
<div id="dpr-w100/natural-questions/train__qrels" class="tab-content">
<div>Query relevance judgment type:</div>
<div class="type">
<div class="type-name">TrecQrel: (<span class="kwd">namedtuple</span>)</div>
<ol class="type-fields">
<li data-tuple-idx="0"><span class="">query_id</span>: <span class="kwd">str</span></li><li data-tuple-idx="1"><span class="">doc_id</span>: <span class="kwd">str</span></li><li data-tuple-idx="2"><span class="">relevance</span>: <span class="kwd">int</span></li><li data-tuple-idx="3"><span class="">iteration</span>: <span class="kwd">str</span></li>
</ol>
</div>
<p>Relevance levels</p>

<table>
<tr><th>Rel.</th><th>Definition</th></tr>
<tr><td class="relScore">-1</td><td>negative samples</td></tr>
<tr><td class="relScore">0</td><td>"hard" negative samples</td></tr>
<tr><td class="relScore">1</td><td>contains the answer text and retrieved in the top BM25 results</td></tr>
<tr><td class="relScore">2</td><td>marked by human annotator as containing the answer</td></tr>
</table>

<p>Example</p>
<code class="example">
<div><span class="kwd">import</span> ir_datasets</div>
<div>dataset = ir_datasets.load(<span class="str">'dpr-w100/natural-questions/train')</div>
<div><span class="kwd">for</span> qrel <span class="kwd">in</span> dataset.qrels_iter():</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;qrel <span class="comment"># namedtuple&lt;query_id, doc_id, relevance, iteration&gt;</span></div>
</code>
</div>

<a class="tab" target="dpr-w100/natural-questions/train__citation">Citation</a>
<div id="dpr-w100/natural-questions/train__citation" class="tab-content">
bibtex:
<cite class="select">@article{Kwiatkowski2019NQ,
  title = {Natural Questions: a Benchmark for Question Answering Research},
  author = {Tom Kwiatkowski and Jennimaria Palomaki and Olivia Redfield and Michael Collins and Ankur Parikh and Chris Alberti and Danielle Epstein and Illia Polosukhin and Matthew Kelcey and Jacob Devlin and Kenton Lee and Kristina N. Toutanova and Llion Jones and Ming-Wei Chang and Andrew Dai and Jakob Uszkoreit and Quoc Le and Slav Petrov},
  year = {2019},
  journal = {TACL}
}
@misc{karpukhin2020dense,
  title={Dense Passage Retrieval for Open-Domain Question Answering},
  author={Vladimir Karpukhin and Barlas Oğuz and Sewon Min and Patrick Lewis and Ledell Wu and Sergey Edunov and Danqi Chen and Wen-tau Yih},
  year={2020},
  eprint={2004.04906},
  archivePrefix={arXiv},
  primaryClass={cs.CL}
}
</cite>
</div>
</div>
</div>

<hr />
<div class="dataset" id="dpr-w100/trivia-qa/dev" data-parent="dpr-w100">
<h3><kbd class="ds-name select"><span class="str">"dpr-w100/trivia-qa/dev"</kdb></h3>

<div class="desc">
 <p> Dev subset from the Trivia QA dataset. Differing from the official Trivia QA collection, this uses the DPR Wikipedia dump as the source collection. Refer to the DPR paper for more details. </p> <ul> <li><a href="https://www.aclweb.org/anthology/P17-1147.pdf">Dataset paper</a></li> <li><a href="http://nlp.cs.washington.edu/triviaqa/">Dataset website</a></li> </ul> 
</div>
<div class="tabs">
<a class="tab" target="dpr-w100/trivia-qa/dev__queries">queries</a>
<div id="dpr-w100/trivia-qa/dev__queries" class="tab-content">
<p>Language: <span class="lang-code">en</span></p>
<div>Query type:</div>
<div class="type">
<div class="type-name">DprW100Query: (<span class="kwd">namedtuple</span>)</div>
<ol class="type-fields">
<li data-tuple-idx="0"><span class="">query_id</span>: <span class="kwd">str</span></li><li data-tuple-idx="1"><span class="">text</span>: <span class="kwd">str</span></li><li data-tuple-idx="2"><span class="">answers</span>: <span class="kwd">Tuple</span>[<span class="kwd">str</span>]</li>
</ol>
</div>
<p>Example</p>
<code class="example">
<div><span class="kwd">import</span> ir_datasets</div>
<div>dataset = ir_datasets.load(<span class="str">'dpr-w100/trivia-qa/dev')</div>
<div><span class="kwd">for</span> query <span class="kwd">in</span> dataset.queries_iter():</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;query <span class="comment"># namedtuple&lt;query_id, text, answers&gt;</span></div>
</code>
</div>

<a class="tab" target="dpr-w100/trivia-qa/dev__docs">docs</a>
<div id="dpr-w100/trivia-qa/dev__docs" class="tab-content">
<p>Language: <span class="lang-code">en</span></p>
<div>Document type:</div>
<div class="type">
<div class="type-name">DprW100Doc: (<span class="kwd">namedtuple</span>)</div>
<ol class="type-fields">
<li data-tuple-idx="0"><span class="">doc_id</span>: <span class="kwd">str</span></li><li data-tuple-idx="1"><span class="">text</span>: <span class="kwd">str</span></li><li data-tuple-idx="2"><span class="">title</span>: <span class="kwd">str</span></li>
</ol>
</div>
<p>Example</p>
<code class="example">
<div><span class="kwd">import</span> ir_datasets</div>
<div>dataset = ir_datasets.load(<span class="str">'dpr-w100/trivia-qa/dev')</div>
<div><span class="kwd">for</span> doc <span class="kwd">in</span> dataset.docs_iter():</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;doc <span class="comment"># namedtuple&lt;doc_id, text, title&gt;</span></div>
</code>
</div>

<a class="tab" target="dpr-w100/trivia-qa/dev__qrels">qrels</a>
<div id="dpr-w100/trivia-qa/dev__qrels" class="tab-content">
<div>Query relevance judgment type:</div>
<div class="type">
<div class="type-name">TrecQrel: (<span class="kwd">namedtuple</span>)</div>
<ol class="type-fields">
<li data-tuple-idx="0"><span class="">query_id</span>: <span class="kwd">str</span></li><li data-tuple-idx="1"><span class="">doc_id</span>: <span class="kwd">str</span></li><li data-tuple-idx="2"><span class="">relevance</span>: <span class="kwd">int</span></li><li data-tuple-idx="3"><span class="">iteration</span>: <span class="kwd">str</span></li>
</ol>
</div>
<p>Relevance levels</p>

<table>
<tr><th>Rel.</th><th>Definition</th></tr>
<tr><td class="relScore">-1</td><td>negative samples</td></tr>
<tr><td class="relScore">0</td><td>"hard" negative samples</td></tr>
<tr><td class="relScore">1</td><td>contains the answer text and retrieved in the top BM25 results</td></tr>
<tr><td class="relScore">2</td><td>marked by human annotator as containing the answer</td></tr>
</table>

<p>Example</p>
<code class="example">
<div><span class="kwd">import</span> ir_datasets</div>
<div>dataset = ir_datasets.load(<span class="str">'dpr-w100/trivia-qa/dev')</div>
<div><span class="kwd">for</span> qrel <span class="kwd">in</span> dataset.qrels_iter():</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;qrel <span class="comment"># namedtuple&lt;query_id, doc_id, relevance, iteration&gt;</span></div>
</code>
</div>

<a class="tab" target="dpr-w100/trivia-qa/dev__citation">Citation</a>
<div id="dpr-w100/trivia-qa/dev__citation" class="tab-content">
bibtex:
<cite class="select">@inproceedings{Joshi2017TriviaQAAL,
  title={TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension},
  author={Mandar Joshi and Eunsol Choi and Daniel S. Weld and Luke Zettlemoyer},
  booktitle={ACL},
  year={2017}
}
@misc{karpukhin2020dense,
  title={Dense Passage Retrieval for Open-Domain Question Answering},
  author={Vladimir Karpukhin and Barlas Oğuz and Sewon Min and Patrick Lewis and Ledell Wu and Sergey Edunov and Danqi Chen and Wen-tau Yih},
  year={2020},
  eprint={2004.04906},
  archivePrefix={arXiv},
  primaryClass={cs.CL}
}
</cite>
</div>
</div>
</div>

<hr />
<div class="dataset" id="dpr-w100/trivia-qa/train" data-parent="dpr-w100">
<h3><kbd class="ds-name select"><span class="str">"dpr-w100/trivia-qa/train"</kdb></h3>

<div class="desc">
 <p> Training subset from the Trivia QA dataset. Differing from the official Trivia QA collection, this uses the DPR Wikipedia dump as the source collection. Refer to the DPR paper for more details. </p> <ul> <li><a href="https://www.aclweb.org/anthology/P17-1147.pdf">Dataset paper</a></li> <li><a href="http://nlp.cs.washington.edu/triviaqa/">Dataset website</a></li> </ul> 
</div>
<div class="tabs">
<a class="tab" target="dpr-w100/trivia-qa/train__queries">queries</a>
<div id="dpr-w100/trivia-qa/train__queries" class="tab-content">
<p>Language: <span class="lang-code">en</span></p>
<div>Query type:</div>
<div class="type">
<div class="type-name">DprW100Query: (<span class="kwd">namedtuple</span>)</div>
<ol class="type-fields">
<li data-tuple-idx="0"><span class="">query_id</span>: <span class="kwd">str</span></li><li data-tuple-idx="1"><span class="">text</span>: <span class="kwd">str</span></li><li data-tuple-idx="2"><span class="">answers</span>: <span class="kwd">Tuple</span>[<span class="kwd">str</span>]</li>
</ol>
</div>
<p>Example</p>
<code class="example">
<div><span class="kwd">import</span> ir_datasets</div>
<div>dataset = ir_datasets.load(<span class="str">'dpr-w100/trivia-qa/train')</div>
<div><span class="kwd">for</span> query <span class="kwd">in</span> dataset.queries_iter():</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;query <span class="comment"># namedtuple&lt;query_id, text, answers&gt;</span></div>
</code>
</div>

<a class="tab" target="dpr-w100/trivia-qa/train__docs">docs</a>
<div id="dpr-w100/trivia-qa/train__docs" class="tab-content">
<p>Language: <span class="lang-code">en</span></p>
<div>Document type:</div>
<div class="type">
<div class="type-name">DprW100Doc: (<span class="kwd">namedtuple</span>)</div>
<ol class="type-fields">
<li data-tuple-idx="0"><span class="">doc_id</span>: <span class="kwd">str</span></li><li data-tuple-idx="1"><span class="">text</span>: <span class="kwd">str</span></li><li data-tuple-idx="2"><span class="">title</span>: <span class="kwd">str</span></li>
</ol>
</div>
<p>Example</p>
<code class="example">
<div><span class="kwd">import</span> ir_datasets</div>
<div>dataset = ir_datasets.load(<span class="str">'dpr-w100/trivia-qa/train')</div>
<div><span class="kwd">for</span> doc <span class="kwd">in</span> dataset.docs_iter():</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;doc <span class="comment"># namedtuple&lt;doc_id, text, title&gt;</span></div>
</code>
</div>

<a class="tab" target="dpr-w100/trivia-qa/train__qrels">qrels</a>
<div id="dpr-w100/trivia-qa/train__qrels" class="tab-content">
<div>Query relevance judgment type:</div>
<div class="type">
<div class="type-name">TrecQrel: (<span class="kwd">namedtuple</span>)</div>
<ol class="type-fields">
<li data-tuple-idx="0"><span class="">query_id</span>: <span class="kwd">str</span></li><li data-tuple-idx="1"><span class="">doc_id</span>: <span class="kwd">str</span></li><li data-tuple-idx="2"><span class="">relevance</span>: <span class="kwd">int</span></li><li data-tuple-idx="3"><span class="">iteration</span>: <span class="kwd">str</span></li>
</ol>
</div>
<p>Relevance levels</p>

<table>
<tr><th>Rel.</th><th>Definition</th></tr>
<tr><td class="relScore">-1</td><td>negative samples</td></tr>
<tr><td class="relScore">0</td><td>"hard" negative samples</td></tr>
<tr><td class="relScore">1</td><td>contains the answer text and retrieved in the top BM25 results</td></tr>
<tr><td class="relScore">2</td><td>marked by human annotator as containing the answer</td></tr>
</table>

<p>Example</p>
<code class="example">
<div><span class="kwd">import</span> ir_datasets</div>
<div>dataset = ir_datasets.load(<span class="str">'dpr-w100/trivia-qa/train')</div>
<div><span class="kwd">for</span> qrel <span class="kwd">in</span> dataset.qrels_iter():</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;qrel <span class="comment"># namedtuple&lt;query_id, doc_id, relevance, iteration&gt;</span></div>
</code>
</div>

<a class="tab" target="dpr-w100/trivia-qa/train__citation">Citation</a>
<div id="dpr-w100/trivia-qa/train__citation" class="tab-content">
bibtex:
<cite class="select">@inproceedings{Joshi2017TriviaQAAL,
  title={TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension},
  author={Mandar Joshi and Eunsol Choi and Daniel S. Weld and Luke Zettlemoyer},
  booktitle={ACL},
  year={2017}
}
@misc{karpukhin2020dense,
  title={Dense Passage Retrieval for Open-Domain Question Answering},
  author={Vladimir Karpukhin and Barlas Oğuz and Sewon Min and Patrick Lewis and Ledell Wu and Sergey Edunov and Danqi Chen and Wen-tau Yih},
  year={2020},
  eprint={2004.04906},
  archivePrefix={arXiv},
  primaryClass={cs.CL}
}
</cite>
</div>
</div>
</div>

<script type="text/javascript">
$(function () {
    $.ajax({
        'url': 'https://smac.pub/irdsdlc?ds=dpr-w100'
    }).done(function (data) {
        $('#Downloads').append(generateDownloads('Downloadable content', data));
    });
});
</script>

</div>
</body>
</html>
